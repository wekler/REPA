{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0ae9d4c39572fe296f8ec491a69527f40957ce295339e47f0d3008358d1ecaa03",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ae9d4c39572fe296f8ec491a69527f40957ce295339e47f0d3008358d1ecaa03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('train.csv') # Arquivo do Titanic\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "y = data['Survived']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X = data.drop('Survived',axis=1) # Coloca todas as colunas no X menos o que já foi colocado em y (Survived)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " PassengerId:  891 int64\n      Pclass:    3 int64\n        Name:  891 object\n         Sex:    2 object\n         Age:  265 float64\n       SibSp:    7 int64\n       Parch:    7 int64\n      Ticket:  681 object\n        Fare:  248 float64\n       Cabin:  148 object\n    Embarked:    4 object\n"
     ]
    }
   ],
   "source": [
    "for column in X.columns:\n",
    "    print(f\"{column:>12}: {len(set(X[column])):4} {X[column].dtype}\") #Imprime o nome da coluna (column:>12). Quantos elementos tem repetitidos em cada coluna (len(set(X[column])) e o tipo de cada coluna (X[column].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "indesejadas = ['PassengerId', 'Name', 'Ticket', 'Cabin'] # Seleciona as características que não serão utilizadas\n",
    "Xdrop = X.drop(indesejadas,axis=1) # Crua Xdrop como o X sem as colunas indesejadas\n",
    "Xdrop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "Xnum = Xdrop.select_dtypes('number') # Separando somente as características que possuem tipo numéricos\n",
    "Xnum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      Pclass: 0\n         Age: 177\n       SibSp: 0\n       Parch: 0\n        Fare: 0\n"
     ]
    }
   ],
   "source": [
    "for column in Xnum.columns:\n",
    "    print(f\"{column:>12}: {sum(Xnum[column].isnull())}\") # Fazer o cálculo de quantos campos estão vazios (Xnum[column].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 3.    , 22.    ,  1.    ,  0.    ,  7.25  ],\n",
       "       [ 1.    , 38.    ,  1.    ,  0.    , 71.2833],\n",
       "       [ 3.    , 26.    ,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [ 3.    , 28.    ,  1.    ,  2.    , 23.45  ],\n",
       "       [ 1.    , 26.    ,  0.    ,  0.    , 30.    ],\n",
       "       [ 3.    , 32.    ,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer # Itilizado para preencher os 177 valores nulos em idade\n",
    "imputer = SimpleImputer(strategy='median') # Será feito uma mediana dos valores de idade e preenchido os valores nulos\n",
    "XnumLimpo = imputer.fit_transform(Xnum)# Comando para executar o que foi programado em Xnum\n",
    "XnumLimpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Sex', 'Embarked'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "Xcat = Xdrop.select_dtypes('object') # Fazendo a mesma coisa para os atributos categóricos\n",
    "Xcat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         Sex: 0\n    Embarked: 2\n"
     ]
    }
   ],
   "source": [
    "for column in Xcat.columns:\n",
    "    print(f\"{column:>12}: {sum(Xcat[column].isnull())}\") # Fazendo a soma de todos os valores que estiverem vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['male', 'S'],\n",
       "       ['female', 'C'],\n",
       "       ['female', 'S'],\n",
       "       ...,\n",
       "       ['female', 'S'],\n",
       "       ['male', 'C'],\n",
       "       ['male', 'Q']], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent') # Configurando como será o preenchimento dos valores vazios, no caso serão preenchidos com os valores mais frequentes\n",
    "XcatLimpo = imputer.fit_transform(Xcat) # Comando para executar o que foi programado em Xcat\n",
    "XcatLimpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<891x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1782 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder # Uma forma de pré-processar \n",
    "encoder = OneHotEncoder()\n",
    "XcatHot = encoder.fit_transform(XcatLimpo) # Realizando o pré-processamento\n",
    "XcatHot # Agora ele retorna uma matriz \"sparsa\", antes tinham 2 colunas e agora tem 5. 2 para o sexo (male e famale) e 3 para Embarked (S, C e Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(891, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import numpy as np \n",
    "Xtratado = np.c_[XnumLimpo,XcatHot.toarray()] # Faz a concatenação (np.c) do XnumLimpo com o XcatHot transformado em um array\n",
    "Xtratado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.columns.isin(test.columns) # Quais colunas tem na base de teste en relação a base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Survived'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train.columns[~train.columns.isin(test.columns)] # Mesmo comando anterior, porem selecionando as colunas que a base de treino nao tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin # Importa para utilizar na criação da classe (necessário para o cross validate?)\n",
    "\n",
    "class AtributosDesejados(BaseEstimator, TransformerMixin): # Classe criada para retirar as colunas indesejadas de forma automática\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasIndesejadas = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop(self.colunasIndesejadas,axis=1)\n",
    "\n",
    "atributosDesejados = AtributosDesejados() # Agora basta criar um objeto da classe\n",
    "Xdrop = atributosDesejados.fit_transform(X) # E executar o transform\n",
    "Xdrop.columns # As colunas idesejadas foram retiradas (mesma coisa que anteriormente, só que agora é reaproveitável)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class AtributosNumericos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasNumericas = X.select_dtypes(include='number').columns # Seleciona de X somente as colunas com tipo numérico\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.colunasNumericas]\n",
    "\n",
    "atributosNumericos = AtributosNumericos() # Agora basta criar um objeto da classe\n",
    "Xnum = atributosNumericos.fit_transform(Xdrop) # E executar o transform\n",
    "Xnum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.82737724, -0.56573646,  0.43279337, -0.47367361, -0.50244517],\n",
       "       [-1.56610693,  0.66386103,  0.43279337, -0.47367361,  0.78684529],\n",
       "       [ 0.82737724, -0.25833709, -0.4745452 , -0.47367361, -0.48885426],\n",
       "       ...,\n",
       "       [ 0.82737724, -0.1046374 ,  0.43279337,  2.00893337, -0.17626324],\n",
       "       [-1.56610693, -0.25833709, -0.4745452 , -0.47367361, -0.04438104],\n",
       "       [ 0.82737724,  0.20276197, -0.4745452 , -0.47367361, -0.49237783]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipenum = Pipeline([ # Criando um pipeline para automatizar as tarefas dos valores numéricos em um conjunto de dados\n",
    "    ('atributos_numericos', AtributosNumericos()), # Seleciona somente os valores numéricos\n",
    "    ('imputer', SimpleImputer(strategy='median')), # Substitui os valores nulos com a mediana dos demais valores\n",
    "    ('scaler', StandardScaler()) # Fazendo a padronização\n",
    "])\n",
    "\n",
    "XnumLimpo = pipenum.fit_transform(Xnum)\n",
    "XnumLimpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Sex', 'Embarked'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class AtributosCategoricos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasCategoricas = X.select_dtypes(include='object').columns # Seleciona de X somente as colunas com tipo categórico (object)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.colunasCategoricas]\n",
    "\n",
    "atributosCategoricos = AtributosCategoricos() # Agora basta criar um objeto da classe\n",
    "Xcat = atributosCategoricos.fit_transform(Xdrop) # E executar o transform\n",
    "Xcat.columns # Agora será exibido somente as colunas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<891x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1782 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "pipecat = Pipeline([ # Criando um pipeline para automatizar as tarefas dos valores categóricos em um conjunto de dados\n",
    "    ('atributos_categoricos', AtributosCategoricos()), # Seleciona somente os valores categóricos\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # Substitui os valores nulos com os valores mais frequentes\n",
    "    ('encoder', OneHotEncoder()) # Colocando o encoder\n",
    "])\n",
    "\n",
    "XcatLimpo = pipecat.fit_transform(Xdrop)\n",
    "XcatLimpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<891x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6237 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "unecaracteristicas = FeatureUnion([ # um pipeline para juntas tanto as características numéricas tratadas quanto as categóricas tratadas\n",
    "    ('pipenum', pipenum), # Reutiliza os pipelines criados anteriormente\n",
    "    ('pipecat', pipecat)\n",
    "])\n",
    "Xtratado = unecaracteristicas.fit_transform(Xdrop)\n",
    "Xtratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<891x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6237 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "preproc = Pipeline([ # Agora o objetivo é receber um X quadrado e já sair totalmente redondo e pronto para usar\n",
    "    ('atributos_desejados', AtributosDesejados()),\n",
    "    ('unecaracteristicas', unecaracteristicas)\n",
    "])\n",
    "Xtratado = preproc.fit_transform(X)\n",
    "Xtratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Usando um classificador em árvore\n",
    "\n",
    "pipetotal = Pipeline([ # A intenção é fazer o pipeline geral dado os dados não tratados ele já faz a predição\n",
    "    ('preproc', preproc),\n",
    "    ('arvore', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pipetotal.fit(X,y) # Faz o fit com X e y\n",
    "ypred = pipetotal.predict(X)\n",
    "accuracy_score(y, ypred) # Faz o processamento, mesmo que superotimista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'fit_time': array([0.02499843, 0.02299929, 0.02700186, 0.02600193, 0.02700043]),\n",
       "  'score_time': array([0.01000071, 0.01000237, 0.00799847, 0.00799823, 0.00800109]),\n",
       "  'test_score': array([0.75977654, 0.78089888, 0.79775281, 0.73595506, 0.80898876])},\n",
       " 0.7766744083861653)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate # Calculando a precisão com o cross_validate\n",
    "import numpy as np\n",
    "\n",
    "scores = cross_validate(pipetotal, X, y)\n",
    "scores, np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'fit_time': array([3.38206029, 3.38500023, 3.32299042, 3.36205196, 3.56403995]),\n",
       "  'score_time': array([0.00694036, 0.00699902, 0.00700569, 0.00599957, 0.00794911]),\n",
       "  'test_score': array([0.82122905, 0.80337079, 0.81460674, 0.78089888, 0.82022472])},\n",
       " 0.8080660347749671)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV # Calculando a precisão utilizando o melhor parâmetro (GridSearch)\n",
    "\n",
    "parametros = {\n",
    "    'arvore__max_depth': [None] + list(range(1,20,2)), # A profundidade máxima da árvore é por padrão vazio (None), mas vai de 1 à 20 de 2 em 2 (1,20,2)\n",
    "    'arvore__criterion': ['gini', 'entropy'] # O critério a ser utilizado é o padrão \"gini\", mas vai testar também utilizando a \"entropy\"\n",
    "}\n",
    "modelo = GridSearchCV(pipetotal, param_grid=parametros)\n",
    "scores = cross_validate(modelo, X, y)\n",
    "scores, np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('preproc', preproc),\n",
    "    ('arvore', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-29-3e0491657120>:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  result['Survived'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "result = test[['PassengerId']]\n",
    "result['Survived'] = y_pred\n",
    "result.to_csv('videoaula.csv',index=False)"
   ]
  }
 ]
}