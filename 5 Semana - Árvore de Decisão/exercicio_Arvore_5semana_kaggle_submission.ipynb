{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0ae9d4c39572fe296f8ec491a69527f40957ce295339e47f0d3008358d1ecaa03",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ae9d4c39572fe296f8ec491a69527f40957ce295339e47f0d3008358d1ecaa03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCRIÇÃO DO EXERCÍCIO 05 - 02\n",
    "\n",
    "# Aluno: Wekler Mendes Sarmento\n",
    "\n",
    "# Para fazer esta atividade você precisará assistir o vídeo https://youtu.be/j8-dT-OoYFs.\n",
    "\n",
    "# Depois você precisará submeter uma predição no Kaggle e salvar a página de submissão em PDF.\n",
    "\n",
    "# Salve o PDF no seu GitHub e coloque o link para entregar a atividade.\n",
    "\n",
    "# A sua nota será o score multiplicado por 100.\n",
    "\n",
    "# Veja o exemplo da minha submissão: \n",
    "# https://github.com/fboldt/aulasml/blob/master/Titanic%20-%20Machine%20Learning%20from%20Disaster%20_%20Kaggle.pdf\n",
    "\n",
    "# Minha nota com essa submissão seria 76.\n",
    "\n",
    "###############################\n",
    "# DEPENDÊNCIAS\n",
    "###############################\n",
    "import pandas as pd # Para a leitura dos dados em arquivo\n",
    "import numpy as np # Para os cálculos aritiméticos\n",
    "from sklearn.metrics import accuracy_score # Para cálculo da precisao SE NECESSÁRIO\n",
    "from sklearn.model_selection import cross_validate # Calculando a precisão com o cross_validate\n",
    "from sklearn.model_selection import GridSearchCV # Calculando a precisão utilizando o melhor parâmetro (GridSearch)\n",
    "from sklearn.tree import DecisionTreeClassifier # Usando um classificador em árvore\n",
    "from sklearn.pipeline import FeatureUnion # Para fazer a união dos dados após tratamento\n",
    "from sklearn.pipeline import Pipeline # Para trabalhar com pipelines\n",
    "from sklearn.impute import SimpleImputer # Substitui os valores nulos de um conjunto baseado em uma condição\n",
    "from sklearn.preprocessing import StandardScaler # Para fazer a padronização dos dados\n",
    "from sklearn.preprocessing import OneHotEncoder # Utilizando o Encoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # Utilizar na criação da classe (necessário para o cross validate)\n",
    "\n",
    "# # Testando\n",
    "# import os\n",
    "# import random\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "################################################################\n",
    "# Importando os dados da planilha de treino e separando em X e y\n",
    "################################################################\n",
    "\n",
    "data = pd.read_csv('train.csv') # Arquivo para treino do Titanic\n",
    "y_train = data['Survived']\n",
    "X_train = data.drop('Survived',axis=1) # Coloca todas as colunas no X menos o que já foi colocado em y (Survived)\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# Importando os dados da planilha de teste e separando em X e y\n",
    "###############################################################\n",
    "\n",
    "X_test = pd.read_csv('test.csv') # Arquivo para teste do Titanic\n",
    "#X_test = data.drop('Survived',axis=1) # Coloca todas as colunas no X menos o que já foi colocado em y (Survived)\n",
    "\n",
    "\n",
    "# Criando uma classe que separa somente as colunas categóricas\n",
    "class AtributosCategoricos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasCategoricas = X.select_dtypes(include='object').columns # Seleciona de X somente as colunas com tipo categórico (object)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.colunasCategoricas]\n",
    "\n",
    "# Criando uma classe que separa somente as colunas numéricas\n",
    "class AtributosNumericos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasNumericas = X.select_dtypes(include='number').columns # Seleciona de X somente as colunas com tipo numérico\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.colunasNumericas]\n",
    "\n",
    "# Criando uma classe que separa somente as colunas desejadas\n",
    "class AtributosDesejados(BaseEstimator, TransformerMixin): # Classe criada para retirar as colunas indesejadas de forma automática\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasIndesejadas = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop(self.colunasIndesejadas,axis=1)\n",
    "\n",
    "pipenum = Pipeline([ # Criando um pipeline para automatizar as tarefas dos valores numéricos em um conjunto de dados\n",
    "    ('atributos_numericos', AtributosNumericos()), # Seleciona somente os valores numéricos\n",
    "    ('imputer', SimpleImputer(strategy='median')), # Substitui os valores nulos com a mediana dos demais valores\n",
    "    ('scaler', StandardScaler()) # Fazendo a padronização\n",
    "])\n",
    "\n",
    "pipecat = Pipeline([ # Criando um pipeline para automatizar as tarefas dos valores categóricos em um conjunto de dados\n",
    "    ('atributos_categoricos', AtributosCategoricos()), # Seleciona somente os valores categóricos\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # Substitui os valores nulos com os valores mais frequentes\n",
    "    ('encoder', OneHotEncoder()) # Colocando o encoder\n",
    "])\n",
    "\n",
    "unecaracteristicas = FeatureUnion([ # um pipeline para juntas tanto as características numéricas tratadas quanto as categóricas tratadas\n",
    "    ('pipenum', pipenum), # Reutiliza os pipelines criados anteriormente\n",
    "    ('pipecat', pipecat)\n",
    "])\n",
    "\n",
    "preproc = Pipeline([ # Agora o objetivo é receber um X quadrado e já sair totalmente redondo e pronto para usar\n",
    "    ('atributos_desejados', AtributosDesejados()),\n",
    "    ('unecaracteristicas', unecaracteristicas)\n",
    "])\n",
    "\n",
    "# Alterado tomando como base o teste do site: https://www.kaggle.com/ihelon/titanic-hyperparameter-tuning-with-gridsearchcv\n",
    "pipetotal = Pipeline([ # A intenção é fazer o pipeline geral dado os dados não tratados ele já faz a predição\n",
    "    ('preproc', preproc),\n",
    "    ('arvore', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "#pipetotal.get_params().keys()\n",
    "\n",
    "parametros = { # Parametros a serem utilizados no GridSearch\n",
    "    'arvore__max_depth': [None] + list(range(1,20,2)), # A profundidade máxima da árvore é por padrão vazio (None), mas vai de 1 à 20 de 2 em 2 (1,20,2)\n",
    "    'arvore__min_samples_split': list(range(2,100)), # Quantidade mínima de amostras\n",
    "    'arvore__splitter':['best','random'], # Forma de divisão dos dados\n",
    "    'arvore__criterion': ['gini', 'entropy'] # O critério a ser utilizado é o padrão \"gini\", mas vai testar também utilizando a \"entropy\"\n",
    "}\n",
    "\n",
    "#grid_scores = ['accuracy','precision']\n",
    "\n",
    "#Teste\n",
    "# parameters_LR = {\n",
    "#     \"arvore__C\": [0.001, 0.01, 0.1, 1.],\n",
    "#     \"arvore__penalty\": [\"l1\", \"l2\"]\n",
    "# }\n",
    "\n",
    "#Teste\n",
    "# def set_seed(seed_value):\n",
    "#     random.seed(seed_value)\n",
    "#     np.random.seed(seed_value)\n",
    "#     os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n",
    "    \n",
    "# #Teste\n",
    "# SEED = 42\n",
    "# set_seed(SEED)\n",
    "\n",
    "#Teste\n",
    "# model_logistic_regression = LogisticRegression(\n",
    "#     random_state=SEED,\n",
    "#     class_weight=\"balanced\",\n",
    "#     solver=\"liblinear\",\n",
    "# )\n",
    "\n",
    "# # Teste\n",
    "# model2_logistic_regression = GridSearchCV(\n",
    "#     model_logistic_regression, \n",
    "#     parameters, \n",
    "#     cv=5,\n",
    "#     scoring='accuracy',\n",
    "# )\n",
    "\n",
    "#modelo = GridSearchCV(pipetotal, param_grid=parametros, scoring=grid_scores, refit='precision', n_jobs=-1)\n",
    "modelo = GridSearchCV(pipetotal, param_grid=parametros, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Teste com o logisticRegression\n",
    "# modelo = GridSearchCV(pipetotal, param_grid=parameters_LR, cv=5, scoring='accuracy')\n",
    "#scores = cross_validate(modelo, X_train, y_train)\n",
    "#scores, np.mean(scores['test_score'])\n",
    "\n",
    "modelo.fit(X_train, y_train) # Treina com a base de treino\n",
    "ypred = modelo.predict(X_test) # E faz a predição com a base de test\n",
    "\n",
    "id_pass = X_test['PassengerId'].astype('int64') # Separa os id's dos passageiros\n",
    "sobreviveu = pd.DataFrame(ypred,columns=['Survived']).astype('int64') # Separa a coluna que indica se o passageiro realmente sobreviveu\n",
    "resultado = pd.concat([id_pass, sobreviveu], axis=1) # Concatena as duas colunas\n",
    "\n",
    "np.savetxt('results_wekler.csv',resultado, delimiter=',', fmt='%i', header='PassengerId,Survived', comments=\"\")\n",
    "\n",
    "\n",
    "\n",
    "###########Primeiro Teste Com DecisionTree\n",
    "# ({'fit_time': array([222.72679496, 219.34800124, 213.90005279, 220.2099483 ,\n",
    "#          227.4420526 ]),\n",
    "#   'score_time': array([0.01006532, 0.00800753, 0.0079987 , 0.00799918, 0.00794864]),\n",
    "#   'test_score': array([0.78461538, 0.86      , 0.79661017, 0.86363636, 0.89130435])},\n",
    "#  0.839233253113872)\n",
    "\n",
    "###########Segundo Teste com LogisticRegression\n",
    "# ({'fit_time': array([1.1089747 , 1.06800556, 1.07797122, 1.07693887, 1.09094667]),\n",
    "#   'score_time': array([0.00702548, 0.00600004, 0.00605154, 0.00705194, 0.00699973]),\n",
    "#   'test_score': array([0.78212291, 0.76404494, 0.79213483, 0.75842697, 0.79775281])},\n",
    "#  0.7788964911179461)\n",
    "\n",
    "###########Terceiro Teste Com DecisionTree\n",
    "# ({'fit_time': array([606.93179226, 590.30258608, 590.89028478, 615.73404241,\n",
    "#          765.35161567]),\n",
    "#   'score_time': array([0.00699878, 0.00699425, 0.00697231, 0.00799799, 0.00794983]),\n",
    "#   'test_score': array([0.79329609, 0.82022472, 0.80898876, 0.78651685, 0.83146067])},\n",
    "#  0.808097420124286)\n",
    "\n"
   ]
  }
 ]
}