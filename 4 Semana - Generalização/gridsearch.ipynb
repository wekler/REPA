{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ae9d4c39572fe296f8ec491a69527f40957ce295339e47f0d3008358d1ecaa03"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_diabetes # Carrega o dataset\n",
    "diabetes = load_diabetes()\n",
    "diabetes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "X, y = diabetes.data, diabetes.target\n",
    "X.shape, y.shape # (442, 10): 442 amostras/exemplos, com 10 características possíveis. (442,): E somente um rótulo/resultado para cada exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[56.2778101  63.42066441 59.63695849 59.59086644 61.70551029]\nSem padronização: 60.126361947859564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_validate # Usar o cross_validate para encontrar os scores\n",
    "\n",
    "# Não usa o KNeighborsClassified, pois a base diabetes, é uma base de regressão. Então tem que ser o KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "modelo = KNeighborsRegressor() # Dentro do parêntesis pode ser colocado manualmente um número, que significa a quantidade de vizinhos. O default é 5.\n",
    "# Essa quantidade de vizinhos sendo alterada, é considerada ruim, pois você está introduzindo um viés no resultado. Como se vc tivesse induzindo um resultado.\n",
    "# Você poderia, por exemplo, ficar trocando os valores para obter um resultado muito melhor do que quando colocar o algorítimo em produçaõ.\n",
    "\n",
    "\n",
    "scores = cross_validate(modelo, X, y, scoring=make_scorer(mean_squared_error, squared=False))\n",
    "\n",
    "print(scores['test_score']) # Imprimindo somente o test_score (retorno de cross_validate?)\n",
    "sempad = np.mean(scores['test_score']) \n",
    "print(f\"Sem padronização: {sempad}\") # imprime A média dos scores sem padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsRegressor(),\n",
       "             param_grid={'n_neighbors': [3, 5, 7]},\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False, squared=False))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Uma forma de ajustar os hiperparâmetros, é utilizar o GridSearch. Que faz o ajuste dos hgiperparâmetros de forma automática. Isso é chamado de auto ML\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parametros = {'n_neighbors': [3,5,7]} # Delimitando os valores próximos ao 5 (default)\n",
    "\n",
    "# A sintaxe padrão do GridSearchCV é: classificador (no caso, o KNeighborsRegressor), os parâmetros e o scoring\n",
    "modelo = GridSearchCV(KNeighborsRegressor(), parametros, scoring=make_scorer(mean_squared_error, greater_is_better=False, squared=False))\n",
    "modelo.fit(X, y) # Depois treina o modelo normalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.001613  , 0.00159984, 0.00159998]),\n",
       " 'std_fit_time': array([0.00078917, 0.00048973, 0.00049004]),\n",
       " 'mean_score_time': array([0.00298734, 0.00260372, 0.00279994]),\n",
       " 'std_score_time': array([0.00109796, 0.00049327, 0.0009798 ]),\n",
       " 'param_n_neighbors': masked_array(data=[3, 5, 7],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 3}, {'n_neighbors': 5}, {'n_neighbors': 7}],\n",
       " 'split0_test_score': array([-58.07341774, -56.2778101 , -56.99180879]),\n",
       " 'split1_test_score': array([-67.43002106, -63.42066441, -62.93518794]),\n",
       " 'split2_test_score': array([-62.28861222, -59.63695849, -59.57483095]),\n",
       " 'split3_test_score': array([-62.02315061, -59.59086644, -55.63774296]),\n",
       " 'split4_test_score': array([-67.25015489, -61.70551029, -60.43146504]),\n",
       " 'mean_test_score': array([-63.41307131, -60.12636195, -59.11420714]),\n",
       " 'std_test_score': array([3.53743647, 2.3951518 , 2.5743976 ]),\n",
       " 'rank_test_score': array([3, 2, 1])}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "modelo.cv_results_ # Será exibido todos os scores das 5 folds (split0 `a split4) que foram testadas, os scores de cada e a médias (mean_test_score) dos scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=7)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "modelo.best_estimator_ # Será exibido o mnelhor estimador que houve no processamento anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "51.15149901888715"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Fazer uma avaliação utilizando a mesma base está errado, o correto seria dividir entre treino e teste. Mas assim mesmo ele fez\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "ypred = modelo.predict(X) # Calcula o ypred utilizando predição\n",
    "mse = mean_squared_error(y, ypred) # calcula o erro (MSE)\n",
    "sqrt(mse) # Tira a raiz quadrada do erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[56.99180879 62.93518794 59.57483095 55.63774296 60.43146504]\nSem padronização: 59.114207135103996\n"
     ]
    }
   ],
   "source": [
    "#Fazendo de uma forma mais justa, mas ainda SEM PADRONIZAÇÃO\n",
    "#### Copiando do cross_validate anterior\n",
    "scores = cross_validate(modelo, X, y, scoring=make_scorer(mean_squared_error, squared=False), return_estimator=True)\n",
    "print(scores['test_score'])\n",
    "sempad = np.mean(scores['test_score'])\n",
    "print(f\"Sem padronização: {sempad}\") # O resultado saiu de 51 para 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'fit_time': array([0.07999849, 0.14000106, 0.08299947, 0.08499861, 0.06400061]),\n",
       " 'score_time': array([0.00300026, 0.00200009, 0.00200033, 0.00200081, 0.00400019]),\n",
       " 'estimator': (GridSearchCV(estimator=KNeighborsRegressor(),\n",
       "               param_grid={'n_neighbors': [3, 5, 7]},\n",
       "               scoring=make_scorer(mean_squared_error, greater_is_better=False, squared=False)),\n",
       "  GridSearchCV(estimator=KNeighborsRegressor(),\n",
       "               param_grid={'n_neighbors': [3, 5, 7]},\n",
       "               scoring=make_scorer(mean_squared_error, greater_is_better=False, squared=False)),\n",
       "  GridSearchCV(estimator=KNeighborsRegressor(),\n",
       "               param_grid={'n_neighbors': [3, 5, 7]},\n",
       "               scoring=make_scorer(mean_squared_error, greater_is_better=False, squared=False)),\n",
       "  GridSearchCV(estimator=KNeighborsRegressor(),\n",
       "               param_grid={'n_neighbors': [3, 5, 7]},\n",
       "               scoring=make_scorer(mean_squared_error, greater_is_better=False, squared=False)),\n",
       "  GridSearchCV(estimator=KNeighborsRegressor(),\n",
       "               param_grid={'n_neighbors': [3, 5, 7]},\n",
       "               scoring=make_scorer(mean_squared_error, greater_is_better=False, squared=False))),\n",
       " 'test_score': array([56.99180879, 62.93518794, 59.57483095, 55.63774296, 60.43146504])}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# A ideia aqui seria juntar o GridSearchCV com o pipeline\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNeighborsRegressor(n_neighbors=7)\nKNeighborsRegressor(n_neighbors=7)\nKNeighborsRegressor(n_neighbors=7)\nKNeighborsRegressor(n_neighbors=7)\nKNeighborsRegressor(n_neighbors=7)\n"
     ]
    }
   ],
   "source": [
    "for estimator in scores['estimator']:\n",
    "    print(estimator.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[56.82092904 63.05450375 60.15515846 54.92728369 59.33477082]\nCom padronização: 58.858529150715086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler # Importando o Scaler\n",
    "from sklearn.pipeline import Pipeline #Importando o Pipeline\n",
    "\n",
    "# Há duas formas de fazer:\n",
    "# A primeira delas é ajustar apenas o estimador no gridsearch e colocar este gridsearch dentro do pipeline. Quando só precisa ajustas os parâmetros do estimador, isso funcionaria muito bem e é rápido. Mas não ajusta o pré-treinamento.\n",
    "# Assim que será desmonstrado agora....\n",
    "\n",
    "#Copiando da sessão anterior...\n",
    "parametros = {'n_neighbors': [3,5,7]}\n",
    "\n",
    "GridSearchKNN = GridSearchCV(KNeighborsRegressor(), parametros, scoring='neg_root_mean_squared_error') # Da um nome para o GridSearchCV com KNN\n",
    "\n",
    "modelo = Pipeline([\n",
    "    (\"padronização\", StandardScaler()), # Faz a padronização utilizando o StandardScaler\n",
    "    (\"gsknn\", GridSearchKNN) # E utilizasr o GridSearchKNN\n",
    "])\n",
    "\n",
    "#Copiando da sessão anterior (sem padronização) só que agora colocando com padronização\n",
    "scores = cross_validate(modelo, X, y, scoring=make_scorer(mean_squared_error, squared=False))\n",
    "print(scores['test_score'])\n",
    "compad = np.mean(scores['test_score'])\n",
    "print(f\"Com padronização: {compad}\") # Imprimindo com padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[56.82092904 63.05450375 60.15515846 54.92728369 59.33477082]\nCom padronização: 58.858529150715086\n"
     ]
    }
   ],
   "source": [
    "# Continuando...\n",
    "# Há duas formas de fazer:\n",
    "# A segunda dela é simular que é necessário fazer algum ajuste pre-treino. No caso coloca-se o pipeline dentro do GridSearchCV. Porémn é mais lento\n",
    "\n",
    "#Copiando da sessão anterior e ajustando...\n",
    "pipeline = Pipeline([ #Antes o modelo era o pipeline, agora o modelo entra no GridSearchCV\n",
    "    (\"padronização\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "parametros = {'knn__n_neighbors': [3,5,7]}\n",
    "\n",
    "modelo = GridSearchCV(pipeline, parametros, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "scores = cross_validate(modelo, X, y, scoring=make_scorer(mean_squared_error, squared=False))\n",
    "print(scores['test_score'])\n",
    "compad = np.mean(scores['test_score'])\n",
    "print(f\"Com padronização: {compad}\")"
   ]
  }
 ]
}